# Google Cloud Storage Setup Guide

## ğŸ¯ Project Configuration

**Project ID**: `lucky-union-463615-t3`  
**Bucket Name**: `degen-digest-data`  
**Region**: Default (us-central1)

## ğŸ”§ Setup Steps

### 1. Authentication Setup

First, ensure you're authenticated with Google Cloud:

```bash
# Check current authentication
gcloud auth list

# If not authenticated, run:
gcloud auth application-default login

# Set the project
gcloud config set project lucky-union-463615-t3

# Verify project is set
gcloud config get-value project
```

### 2. Enable Required APIs

Enable the Cloud Storage API:

```bash
gcloud services enable storage.googleapis.com
```

### 3. Test Setup

Run the test script to verify everything is working:

```bash
python test_cloud_setup.py
```

This will:
- âœ… Test Google Cloud Storage imports
- âœ… Verify authentication
- âœ… Check bucket access
- âœ… List existing files (if any)
- âœ… Test local data files

## ğŸš€ Usage Commands

### List Cloud Files
```bash
python scripts/cloud_storage_sync.py --list
```

### Upload All Data to Cloud
```bash
python scripts/cloud_storage_sync.py --direction upload
```

### Download All Data from Cloud
```bash
python scripts/cloud_storage_sync.py --direction download
```

### Create Database Backup
```bash
python scripts/cloud_storage_sync.py --backup
```

### Restore Database from Backup
```bash
python scripts/cloud_storage_sync.py --restore 20250630_154312
```

### Bidirectional Sync (Upload + Download)
```bash
python scripts/cloud_storage_sync.py --direction both
```

## ğŸ“ Cloud Storage Structure

The data will be organized in the cloud bucket as follows:

```
degen-digest-data/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ twitter_raw.json
â”‚   â”œâ”€â”€ reddit_raw.json
â”‚   â”œâ”€â”€ telegram_raw.json
â”‚   â”œâ”€â”€ newsapi_raw.json
â”‚   â”œâ”€â”€ coingecko_raw.json
â”‚   â”œâ”€â”€ enhanced_twitter_data.json
â”‚   â”œâ”€â”€ health_metrics.json
â”‚   â”œâ”€â”€ health_alerts.json
â”‚   â””â”€â”€ consolidated_data.json
â”œâ”€â”€ database/
â”‚   â””â”€â”€ degen_digest.db
â”œâ”€â”€ enhanced_pipeline/
â”‚   â”œâ”€â”€ viral_predictions.json
â”‚   â”œâ”€â”€ processed_data.json
â”‚   â”œâ”€â”€ summary_report.json
â”‚   â”œâ”€â”€ trends_analysis.json
â”‚   â””â”€â”€ pipeline_stats.json
â””â”€â”€ backups/
    â””â”€â”€ degen_digest_YYYYMMDD_HHMMSS.db
```

## ğŸ” Dashboard Integration

The Data Sync dashboard page provides:

1. **Visual Data Overview**: Charts showing data distribution
2. **Sync Status**: Real-time file status monitoring
3. **One-Click Operations**: Buttons for merge, upload, download
4. **Analytics**: Enhanced viral predictions and trends
5. **Export Tools**: Download data as JSON or CSV

Access via: `http://localhost:8501` â†’ "Data Sync" page

## ğŸ› ï¸ Troubleshooting

### Authentication Issues
```bash
# Re-authenticate
gcloud auth application-default login

# Check credentials
gcloud auth list
```

### Permission Issues
```bash
# Check if you have storage admin role
gcloud projects get-iam-policy lucky-union-463615-t3
```

### Bucket Creation Issues
```bash
# Create bucket manually
gsutil mb gs://degen-digest-data

# Set bucket permissions
gsutil iam ch allUsers:objectViewer gs://degen-digest-data
```

### Import Errors
```bash
# Reinstall Google Cloud Storage
pip install --upgrade google-cloud-storage
```

## ğŸ“Š Data Sync Workflow

### Daily Workflow
1. **Run Scrapers**: Collect fresh data
2. **Merge Data**: `python scripts/merge_local_cloud_data.py`
3. **Upload to Cloud**: `python scripts/cloud_storage_sync.py --direction upload`
4. **Check Dashboard**: Verify data in Data Sync page

### Recovery Workflow
1. **Download from Cloud**: `python scripts/cloud_storage_sync.py --direction download`
2. **Verify Data**: Check file integrity
3. **Restore if Needed**: Use backup restoration

## ğŸ” Security Considerations

- **Access Control**: Bucket is private by default
- **Backup Strategy**: Database backups stored in cloud
- **Data Encryption**: All data encrypted at rest
- **Audit Logging**: Access logs available in Cloud Console

## ğŸ“ˆ Monitoring

### Cloud Console Monitoring
- Go to: https://console.cloud.google.com/storage/browser
- Select bucket: `degen-digest-data`
- Monitor usage, access patterns, and costs

### Local Monitoring
- Check `output/merge_report.json` for sync status
- Use Data Sync dashboard for real-time monitoring
- Review logs in `logs/degen_digest.log`

## ğŸ‰ Success Indicators

âœ… **Authentication**: `gcloud auth list` shows active account  
âœ… **Project Access**: `gcloud config get-value project` returns correct ID  
âœ… **Bucket Access**: `gsutil ls gs://degen-digest-data` works  
âœ… **Data Sync**: Files upload/download successfully  
âœ… **Dashboard**: Data Sync page shows all data  

---

*Setup completed for project: lucky-union-463615-t3* 